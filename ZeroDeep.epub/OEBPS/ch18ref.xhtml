<?xml version="1.0" encoding="UTF-8"?>
<html xmlns:epub='http://www.idpf.org/2007/ops' xml:lang='ja' xmlns:ops='http://www.idpf.org/2007/ops' xmlns='http://www.w3.org/1999/xhtml'>
<head>
  <meta charset='UTF-8'/>
  <link href='oreilly.css' rel='stylesheet' type='text/css'/>
  <meta content='Re:VIEW' name='generator'/>
  <title>参考文献</title>
</head>
<body>
<h1 id='h'>参考文献</h1>
<div class='bib'>
<h3 id='h-0-1'>Python / NumPy</h3>
<ul>
<li>［1］ Bill Lubanovic：『Introducing Python』O'Reilly Media刊、2014年（邦題『入門 Python 3』斎藤康毅 監訳、長尾高弘 訳、オライリー・ジャパン刊）</li>
<li>［2］ Wes McKinney：『Python for Data Analysis』O'Reilly Media刊、2012年（邦題『Pythonによるデータ分析入門——NumPy、pandasを使ったデータ処理』小林儀匡、鈴木宏尚、瀬戸山雅人、滝口開資、野上大介 訳、オライリー・ジャパン刊）</li>
<li>［3］ Scipy Lecture Notes（<a class='link' href='http://www.turbare.net/transl/scipy-lecture-notes/index.html'>http://www.turbare.net/transl/scipy-lecture-notes/index.html</a>）</li>
</ul>

<h3 id='h-0-2'>計算グラフ（誤差逆伝播法）</h3>
<ul>
<li>［4］ Andrej Karpathy's blog &quot;Hacker's guide to Neural Networks&quot;（<a class='link' href='http://karpathy.github.io/neuralnets/'>http://karpathy.github.io/neuralnets/</a>）</li>
</ul>

<h3 id='h-0-3'>Deep Learningのオンライン授業（資料）</h3>
<ul>
<li>［5］ CS231n: Convolutional Neural Networks for Visual Recognition（<a class='link' href='http://cs231n.github.io/'>http://cs231n.github.io/</a>）</li>
</ul>

<h3 id='h-0-4'>パラメータの更新方法</h3>
<ul>
<li>［6］ John Duchi, Elad Hazan, and Yoram Singer（2011）：Adaptive Subgradient Methods for Online Learning and Stochastic Optimization. Journal of Machine Learning Research 12, Jul (2011), 2121–2159.</li>
<li>［7］ Tieleman, T., &amp; Hinton, G.（2012）：Lecture 6.5―RMSProp: Divide the gradient by a running average of its recent magnitude. COURSERA: Neural Networks for Machine Learning.</li>
<li>［8］ Diederik Kingma and Jimmy Ba.（2014）：Adam: A Method for Stochastic Optimization. arXiv:1412.6980［cs］(December 2014).</li>
</ul>

<h3 id='h-0-5'>重みパラメータの初期値</h3>
<ul>
<li>［9］ Xavier Glorot and Yoshua Bengio（2010）：Understanding the difficulty of training deep feedforward neural networks. In Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS2010). Society for Artificial Intelligence and Statistics.</li>
<li>［10］ Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun（2015）：Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification. In 1026–1034.</li>
</ul>

<h3 id='h-0-6'>Batch Normalization / Dropout</h3>
<ul>
<li>［11］ Sergey Ioffe and Christian Szegedy（2015）：Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. arXiv:1502.03167［cs］(February 2015).</li>
<li>［12］ Dmytro Mishkin and Jiri Matas（2015）：All you need is a good init. arXiv:1511.06422［cs］(November 2015).</li>
<li>［13］ Frederik Kratzert's blog &quot;Understanding the backward pass through Batch Normalization Layer&quot;（<a class='link' href='https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html'>https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html</a>）</li>
<li>［14］ N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov（2014）：Dropout: A simple way to prevent neural networks from overfitting. The Journal of Machine Learning Research, pages 1929–1958, 2014.</li>
</ul>

<h3 id='h-0-7'>ハイパーパラメータの最適化</h3>
<ul>
<li>［15］ James Bergstra and Yoshua Bengio（2012）：Random Search for Hyper-Parameter Optimization. Journal of Machine Learning Research 13, Feb (2012), 281–305.</li>
<li>［16］ Jasper Snoek, Hugo Larochelle, and Ryan P. Adams（2012）：Practical Bayesian Optimization of Machine Learning Algorithms. In F. Pereira, C. J. C. Burges, L. Bottou, &amp; K. Q. Weinberger, eds. Advances in Neural Information Processing Systems 25. Curran Associates, Inc., 2951–2959.</li>
</ul>

<h3 id='h-0-8'>CNNの可視化</h3>
<ul>
<li>［17］ Matthew D. Zeiler and Rob Fergus（2014）：Visualizing and Understanding Convolutional Networks. In David Fleet, Tomas Pajdla, Bernt Schiele, &amp; Tinne Tuytelaars, eds. Computer Vision – ECCV 2014. Lecture Notes in Computer Science. Springer International Publishing, 818–833.</li>
<li>［18］ A. Mahendran and A. Vedaldi（2015）：Understanding deep image representations by inverting them. In 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 5188–5196. DOI:（<a class='link' href='http://dx.doi.org/10.1109/CVPR.2015.7299155'>http://dx.doi.org/10.1109/CVPR.2015.7299155</a>）</li>
<li>［19］ Donglai Wei, Bolei Zhou, Antonio Torralba, William T. Freeman（2015）：mNeuron: A Matlab Plugin to Visualize Neurons from Deep Models（<a class='link' href='http://vision03.csail.mit.edu/cnn_art/index.html#v_single'>http://vision03.csail.mit.edu/cnn_art/index.html#v_single</a>）</li>
</ul>

<h3 id='h-0-9'>代表的なネットワーク</h3>
<ul>
<li>［20］ Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner（1998）：Gradient-based learning applied to document recognition. Proceedings of the IEEE 86, 11 (November 1998), 2278–2324. DOI:（<a class='link' href='http://dx.doi.org/10.1109/5.726791'>http://dx.doi.org/10.1109/5.726791</a>）</li>
<li>［21］ Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton（2012）：ImageNet Classification with Deep Convolutional Neural Networks. In F. Pereira, C. J. C. Burges, L. Bottou, &amp; K. Q. Weinberger, eds. Advances in Neural Information Processing Systems 25. Curran Associates, Inc., 1097–1105.</li>
<li>［22］ Karen Simonyan and Andrew Zisserman（2014）：Very Deep Convolutional Networks for Large-Scale Image Recognition. arXiv:1409.1556［cs］(September 2014).</li>
<li>［23］ Christian Szegedy et al（2015）：Going Deeper With Convolutions. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR).</li>
<li>［24］ Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun（2015）：Deep Residual Learning for Image Recognition. arXiv:1512.03385［cs］(December 2015).</li>
</ul>

<h3 id='h-0-10'>データセット</h3>
<ul>
<li>［25］ J. Deng, W. Dong, R. Socher, L.J. Li, Kai Li, and Li Fei-Fei（2009）：ImageNet: A large-scale hierarchical image database. In IEEE Conference on Computer Vision and Pattern Recognition, 2009. CVPR 2009. 248–255. DOI:（<a class='link' href='http://dx.doi.org/10.1109/CVPR.2009.5206848'>http://dx.doi.org/10.1109/CVPR.2009.5206848</a>）</li>
</ul>

<h3 id='h-0-11'>計算の高速化</h3>
<ul>
<li>［26］ Jia Yangqing（2014）：Learning Semantic Image Representations at a Large Scale. PhD thesis, EECS Department, University of California, Berkeley, May 2014.（<a class='link' href='http://www.eecs.berkeley.edu/Pubs/TechRpts/2014/EECS-2014-93.html'>http://www.eecs.berkeley.edu/Pubs/TechRpts/2014/EECS-2014-93.html</a>）</li>
<li>［27］ NVIDIA blog &quot;NVIDIA Propels Deep Learning with TITAN X, New DIGITS Training System and DevBox&quot;（<a class='link' href='https://blogs.nvidia.com/blog/2015/03/17/digits-devbox/'>https://blogs.nvidia.com/blog/2015/03/17/digits-devbox/</a>）</li>
<li>［28］ Google Research Blog &quot;Announcing TensorFlow 0.8 – now with distributed computing support!&quot;（<a class='link' href='http://googleresearch.blogspot.jp/2016/04/announcing-tensorflow-08-now-with.html'>http://googleresearch.blogspot.jp/2016/04/announcing-tensorflow-08-now-with.html</a>）</li>
<li>［29］ Martín Abadi et al（2016）：TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems. arXiv:1603.04467［cs］(March 2016).</li>
<li>［30］ Suyog Gupta, Ankur Agrawal, Kailash Gopalakrishnan, and Pritish Narayanan（2015）：Deep learning with limited numerical precision. CoRR, abs/1502.02551 392 (2015).</li>
<li>［31］ Matthieu Courbariaux and Yoshua Bengio（2016）：Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1. arXiv preprint arXiv:1602.02830 (2016).</li>
</ul>

<h3 id='h-0-12'>MNISTデータセットの精度ランキングおよび最高精度の手法</h3>
<ul>
<li>［32］ Rodrigo Benenson's blog &quot;Classification datasets results&quot;（<a class='link' href='http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html'>http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html</a>）</li>
<li>［33］ Li Wan, Matthew Zeiler, Sixin Zhang, Yann L. Cun, and Rob Fergus（2013）：Regularization of Neural Networks using DropConnect. In Sanjoy Dasgupta &amp; David McAllester, eds. Proceedings of the 30th International Conference on Machine Learning (ICML2013). JMLR Workshop and Conference Proceedings, 1058–1066.</li>
</ul>

<h3 id='h-0-13'>ディープラーニングのアプリケーション</h3>
<ul>
<li>［34］ Visual Object Classes Challenge 2012 (VOC2012)（<a class='link' href='http://host.robots.ox.ac.uk/pascal/VOC/voc2012/'>http://host.robots.ox.ac.uk/pascal/VOC/voc2012/</a>）</li>
<li>［35］ Ross Girshick, Jeff Donahue, Trevor Darrell, and Jitendra Malik（2014）：Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation. In 580–587.</li>
<li>［36］ Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun（2015）：Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, &amp; R. Garnett, eds. Advances in Neural Information Processing Systems 28. Curran Associates, Inc., 91–99.</li>
<li>［37］ Jonathan Long, Evan Shelhamer, and Trevor Darrell（2015）：Fully Convolutional Networks for Semantic Segmentation. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR).</li>
<li>［38］ Oriol Vinyals, Alexander Toshev, Samy Bengio, and Dumitru Erhan（2015）：Show and Tell: A Neural Image Caption Generator. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR).</li>
<li>［39］ Leon A. Gatys, Alexander S. Ecker, and Matthias Bethge（2015）：A Neural Algorithm of Artistic Style. arXiv:1508.06576［cs, q-bio］(August 2015).</li>
<li>［40］ neural-style &quot;Torch implementation of neural style algorithm&quot;（<a class='link' href='https://github.com/jcjohnson/neural-style/'>https://github.com/jcjohnson/neural-style/</a>）</li>
<li>［41］ Alec Radford, Luke Metz, and Soumith Chintala（2015）：Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. arXiv:1511.06434［cs］(November 2015).</li>
<li>［42］ Vijay Badrinarayanan, Kendall, and Roberto Cipolla（2015）：SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation. arXiv preprint arXiv:1511.00561 (2015).</li>
<li>［43］ SegNet Demo page（<a class='link' href='http://mi.eng.cam.ac.uk/projects/segnet/'>http://mi.eng.cam.ac.uk/projects/segnet/</a>）</li>
<li>［44］ Volodymyr Mnih et al（2015）：Human-level control through deep reinforcement learning. Nature 518, 7540 (2015), 529–533.</li>
<li>［45］ David Silver et al（2016）：Mastering the game of Go with deep neural networks and tree search. Nature 529, 7587 (2016), 484–489.</li>
</ul>
</div></body>
</html>
